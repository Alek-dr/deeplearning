{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from numpy import genfromtxt\n",
    "\n",
    "\n",
    "# Load in training and testing data\n",
    "# Shape of (record_num, col_num): (999,7)\n",
    "\n",
    "my_data = genfromtxt('Data/s10_s23_train_datab.csv', delimiter=',')\n",
    "my_testing = genfromtxt('Data/s10_s23_test_datab.csv', delimiter=',')\n",
    "my_real = genfromtxt('Data/s10_s23_test_datab.csv', delimiter=',')\n",
    "\n",
    "\n",
    "category = 1\n",
    "\n",
    "factor = 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# batch function\n",
    "def my_batch(category,num,my_data):\n",
    "#     choose a num of batch return x, y as vectors\n",
    "    size,col = my_data.shape\n",
    "    idList = random.sample(range(0, size), num )\n",
    "    batch_xs = np.zeros(shape=(num,col-category))\n",
    "    batch_ys = np.zeros(shape=(num,category))\n",
    "    \n",
    "    for index,i in enumerate(idList):\n",
    "        line = my_data[i,:-category]\n",
    "        batch_xs[index]=line\n",
    "        label = my_data[i,col-category:col]\n",
    "        batch_ys[index]=label\n",
    "    return batch_xs,batch_ys\n",
    "    \n",
    "def testingDataLoader(category,my_data):\n",
    "    size,col = my_data.shape\n",
    "    \n",
    "    batch_xs = np.zeros(shape=(size,col-category))\n",
    "    batch_ys = np.zeros(shape=(size,category))\n",
    "    for index,line in enumerate(my_data):\n",
    "        batch_xs[index]=line[:-category]\n",
    "        batch_ys[index]=line[col-category:col]\n",
    "\n",
    "        \n",
    "    return batch_xs,batch_ys\n",
    "\n",
    "# get real data\n",
    "def realDataLoader(category,my_data):\n",
    "    size,col = my_data.shape\n",
    "    batch_xs = np.zeros(shape=(size,col-category))\n",
    "    for index,line in enumerate(my_data):\n",
    "        batch_xs[index]=line[:-category]\n",
    "    print size,col-category\n",
    "    return batch_xs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y <class 'tensorflow.python.framework.ops.Tensor'>\n",
      "Now  0\n",
      "Now  100\n",
      "Now  200\n",
      "Now  300\n",
      "Now  400\n",
      "Now  500\n",
      "Now  600\n",
      "Now  700\n",
      "Now  800\n",
      "Now  900\n",
      "Now  1000\n",
      "Now  1100\n",
      "Now  1200\n",
      "Now  1300\n",
      "Now  1400\n",
      "Now  1500\n",
      "Now  1600\n",
      "Now  1700\n",
      "Now  1800\n",
      "Now  1900\n",
      "Now  2000\n",
      "Now  2100\n",
      "Now  2200\n",
      "Now  2300\n",
      "Now  2400\n",
      "Now  2500\n",
      "Now  2600\n",
      "Now  2700\n",
      "Now  2800\n",
      "Now  2900\n",
      "Now  3000\n",
      "Now  3100\n",
      "Now  3200\n",
      "Now  3300\n",
      "Now  3400\n",
      "Now  3500\n",
      "Now  3600\n",
      "Now  3700\n",
      "Now  3800\n",
      "Now  3900\n",
      "Now  4000\n",
      "Now  4100\n",
      "Now  4200\n",
      "Now  4300\n",
      "Now  4400\n",
      "Now  4500\n",
      "Now  4600\n",
      "Now  4700\n",
      "Now  4800\n",
      "Now  4900\n",
      "Now  5000\n",
      "Now  5100\n",
      "Now  5200\n",
      "Now  5300\n",
      "Now  5400\n",
      "Now  5500\n",
      "Now  5600\n",
      "Now  5700\n",
      "Now  5800\n",
      "Now  5900\n",
      "Now  6000\n",
      "Now  6100\n",
      "Now  6200\n",
      "Now  6300\n",
      "Now  6400\n",
      "Now  6500\n",
      "Now  6600\n",
      "Now  6700\n",
      "Now  6800\n",
      "Now  6900\n",
      "Now  7000\n",
      "Now  7100\n",
      "Now  7200\n",
      "Now  7300\n",
      "Now  7400\n",
      "Now  7500\n",
      "Now  7600\n",
      "Now  7700\n",
      "Now  7800\n",
      "Now  7900\n",
      "Now  8000\n",
      "Now  8100\n",
      "Now  8200\n",
      "Now  8300\n",
      "Now  8400\n",
      "Now  8500\n",
      "Now  8600\n",
      "Now  8700\n",
      "Now  8800\n",
      "Now  8900\n",
      "Now  9000\n",
      "Now  9100\n",
      "Now  9200\n",
      "Now  9300\n",
      "Now  9400\n",
      "Now  9500\n",
      "Now  9600\n",
      "Now  9700\n",
      "Now  9800\n",
      "Now  9900\n"
     ]
    }
   ],
   "source": [
    "# Implementation starts!\n",
    "\n",
    "num_hidden = 256\n",
    "\n",
    "# None means any number, so x is not a specific number here.\n",
    "x = tf.placeholder(tf.float32, [None, factor],name=\"x-input\")\n",
    "\n",
    "\n",
    "# Init weights, bias, (all zeros first) and define softmax function\n",
    "W = tf.Variable(tf.zeros([factor, category]),name=\"weights\")\n",
    "b = tf.Variable(tf.zeros([category],name=\"bias\"))\n",
    "\n",
    "\n",
    "# Variables.\n",
    "layer1_weights = tf.Variable(tf.truncated_normal(\n",
    "      [factor, num_hidden], stddev=0.1))\n",
    "layer1_biases = tf.Variable(tf.zeros([num_hidden]))\n",
    "\n",
    "layer2_weights = tf.Variable(tf.truncated_normal(\n",
    "      [num_hidden,category], stddev=0.1))\n",
    "layer2_biases = tf.Variable(tf.zeros([category]))\n",
    "\n",
    "# dropout\n",
    "keep_prob = tf.placeholder(\"float\")\n",
    "\n",
    "\n",
    "\n",
    "# use a name scope to organize nodes in the graph visualizer\n",
    "with tf.name_scope(\"Wx_b\") as scope:\n",
    "# ------------------------------------------------------------------------------------------------------------------\n",
    "# first multiply x and w, then add b vector. apply softmax to get probabilities\n",
    "#   y = tf.nn.softmax(tf.matmul(x, W) + b)\n",
    "#     y = tf.matmul(x, W) + b\n",
    "    \n",
    "    hidden = tf.matmul(x,layer1_weights)+layer1_biases\n",
    "    \n",
    "#     hidden = tf.nn.softmax(hidden)\n",
    "\n",
    "# dropout\n",
    "    hidden = tf.nn.dropout(hidden, keep_prob)\n",
    "\n",
    "    y = tf.matmul(hidden,layer2_weights)+layer2_biases\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "print \"y\",type(y)\n",
    "\n",
    "# Add summary ops to collect data\n",
    "w_hist = tf.histogram_summary(\"weights\", W)\n",
    "b_hist = tf.histogram_summary(\"biases\", b)\n",
    "y_hist = tf.histogram_summary(\"y\", y)\n",
    "\n",
    "\n",
    "weights_summary = tf.histogram_summary(\"weights\", W)\n",
    "biases_summary = tf.histogram_summary(\"biases\", b)\n",
    "y_summary = tf.histogram_summary(\"y\", y)\n",
    "\n",
    "\n",
    "\n",
    "# Out put\n",
    "y_ = tf.placeholder(tf.float32, [None, category],name=\"y-input\")\n",
    "\n",
    "with tf.name_scope(\"xent\") as scope:\n",
    "# ------------------------------------------------------------------------------------------------------------------\n",
    "# tf.log computes logarithm of each element. Cost Function.\n",
    "#   cross_entropy = -tf.reduce_sum(y_*tf.log(y))\n",
    "    gap = tf.sub(y,y_)\n",
    "    cross_entropy = tf.reduce_sum(tf.abs(gap))\n",
    "    \n",
    "with tf.name_scope(\"train\") as scope:\n",
    "# minimize cross_entropy using the gradient descent algorithm with a learning rate of 0.01. \n",
    "  train_step = tf.train.GradientDescentOptimizer(0.0001).minimize(cross_entropy)\n",
    "\n",
    "# # Learning rate decay\n",
    "#   global_step = tf.Variable(0, trainable=False)\n",
    "#   starter_learning_rate = 0.001\n",
    "#   learning_rate = tf.train.exponential_decay(starter_learning_rate, global_step,\n",
    "#                                            100000, 0.96, staircase=True)\n",
    "#   train_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(cross_entropy)\n",
    "\n",
    "\n",
    "\n",
    "  \n",
    "init = tf.initialize_all_variables()\n",
    "\n",
    "# launch the model in a Session, run the initialized operation\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "# Train for 1000 times!\n",
    "# batch of 100 at each time\n",
    "# train_step feeding in the batches data to replace the placeholders\n",
    "for i in range(10000):\n",
    "\n",
    "\n",
    "  batch_xs, batch_ys = my_batch(category,100, my_data)\n",
    "  feed = {x: batch_xs, y_: batch_ys,keep_prob:0.5}\n",
    "\n",
    "  if i%100 == 0:\n",
    "#     train_accuracy = accuracy.eval(session=sess, feed_dict=feed)\n",
    "#     print \"type \",tf.shape(accuracy)\n",
    "#     print \"value \",train_accuracy\n",
    "#     print \"step %d, training accuracy %g\"%(i, train_accuracy)\n",
    "    print \"Now \",i\n",
    "  train_step.run(session=sess, feed_dict=feed)\n",
    "\n",
    "\n",
    "# In[21]:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "  \n",
    "# Merge all the summaries and write them out to /tmp/mnist_logs\n",
    "merged = tf.merge_summary([weights_summary, biases_summary, y_summary])\n",
    "writer = tf.train.SummaryWriter(\"/tmp/read2\", sess.graph_def)\n",
    "tf.train.SummaryWriter(\"/tmp/read2\", sess.graph_def).flush()\n",
    "# tf.train.SummaryWriter.flush()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# Evaluating\n",
    "with tf.name_scope(\"test\") as scope:\n",
    "# evaluation\n",
    "    y_shaped = tf.reshape(y,[-1])\n",
    "    y__shaped = tf.reshape(y_,[-1])\n",
    "    norm1= tf.sqrt(tf.reduce_sum(tf.square(y_shaped),keep_dims=True))\n",
    "    norm2= tf.sqrt(tf.reduce_sum(tf.square(y__shaped),keep_dims=True))\n",
    "    dot = tf.reduce_sum(tf.mul(y_shaped,y__shaped))\n",
    "    cos = abs(dot)/tf.mul(norm1,norm2)\n",
    "    accuracy = tf.reduce_sum(cos)\n",
    "#     results = tf.reduce_sum(y__shaped)\n",
    " \n",
    "\n",
    "# get testing data\n",
    "test_xs,test_ys = testingDataLoader(category,my_testing)\n",
    "\n",
    "\n",
    "# Train for 1000 times!\n",
    "# batch of 100 at each time\n",
    "# train_step feeding in the batches data to replace the placeholders\n",
    "# for i in range(10000):\n",
    "\n",
    "\n",
    "#   batch_xs, batch_ys = my_batch(category,100, my_data)\n",
    "#   feed = {x: batch_xs, y_: batch_ys}\n",
    "\n",
    "#   if i%100 == 0:\n",
    "#     train_accuracy = accuracy.eval(session=sess, feed_dict=feed)\n",
    "#     print \"type \",tf.shape(accuracy)\n",
    "#     print \"value \",train_accuracy\n",
    "#     print \"step %d, training accuracy %g\"%(i, train_accuracy)\n",
    "#   train_step.run(session=sess, feed_dict=feed)\n",
    "\n",
    "\n",
    "#     batch_xs, batch_ys = my_batch(category,100, my_data)\n",
    "#     feed = {x: batch_xs, y_: batch_ys}\n",
    "#     sess.run(train_step, feed_dict=feed)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.445564\n"
     ]
    }
   ],
   "source": [
    "  \n",
    "    \n",
    "# test_xs,test_ys = testingDataLoader(category,my_testing)\n",
    "# Accuracy\n",
    "print sess.run(accuracy, feed_dict={x: test_xs, y_: test_ys,keep_prob:1.0})\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# https://github.com/tensorflow/tensorflow/issues/97\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202 5\n",
      "[[  13.     1.    10.     0.    20.7]\n",
      " [  12.     5.     9.     0.     7. ]\n",
      " [  19.     4.     5.     0.   689.6]\n",
      " ..., \n",
      " [  23.     7.     8.     0.    11.8]\n",
      " [  21.     6.     6.     0.     2.7]\n",
      " [  22.     1.     9.     0.     6. ]]\n",
      "[[0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]]\n"
     ]
    }
   ],
   "source": [
    "# print sess.run(accuracy, feed_dict={x: test_xs, y_: test_ys})\n",
    "# apply!\n",
    "\n",
    "# get real data\n",
    "test_real = realDataLoader(category,my_real)\n",
    "print test_real\n",
    "\n",
    "# \n",
    "real = tf.placeholder(tf.float32, [None, factor],name=\"x-test\")\n",
    "\n",
    "with tf.name_scope(\"apply\") as scope:\n",
    "    results = tf.to_int64(tf.matmul(real, W)+b)\n",
    "    \n",
    "    accuracy = results\n",
    " \n",
    "print sess.run(accuracy,feed_dict={real:test_real})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
